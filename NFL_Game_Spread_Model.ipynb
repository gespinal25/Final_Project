{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c5e0691",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import warnings\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\",category=DeprecationWarning)\n",
    "    import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25d99ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.metrics import brier_score_loss, roc_auc_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.calibration import CalibratedClassifierCV as CCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, VotingClassifier\n",
    "import xgboost as xgb\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cac1976d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('spreadspoke_scores.csv', encoding='utf-8')\n",
    "teams = pd.read_csv('nfl_teams.csv', encoding='utf-8')\n",
    "games_elo = pd.read_csv('nfl_elo.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bfe26085",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.replace(r'^\\s*$', np.nan, regex=True)\n",
    "\n",
    "# removing rows from specific columns that have null values, resetting index and changing data types\n",
    "df = df[(df.score_home.isnull() == False) & (df.team_favorite_id.isnull() == False) & (df.over_under_line.isnull() == False) &\n",
    "        (df.schedule_season >= 1979)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13b53827",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(drop=True, inplace=True)\n",
    "df['over_under_line'] = df.over_under_line.astype(float)\n",
    "\n",
    "# mapping team_id to the correct teams\n",
    "df['team_home'] = df.team_home.map(teams.set_index('team_name')['team_id'].to_dict())\n",
    "df['team_away'] = df.team_away.map(teams.set_index('team_name')['team_id'].to_dict())\n",
    "\n",
    "# fix team_favorite_id for Colts in 1969 and 1971 SB\n",
    "df.loc[(df.schedule_season == 1968) & (df.schedule_week == 'Superbowl'), 'team_favorite_id'] = 'IND'\n",
    "df.loc[(df.schedule_season == 1970) & (df.schedule_week == 'Superbowl'), 'team_favorite_id'] = 'IND'\n",
    "\n",
    "# creating home favorite and away favorite columns (fill na with 0's)\n",
    "df.loc[df.team_favorite_id == df.team_home, 'home_favorite'] = 1\n",
    "df.loc[df.team_favorite_id == df.team_away, 'away_favorite'] = 1\n",
    "df.home_favorite.fillna(0, inplace=True)\n",
    "df.away_favorite.fillna(0, inplace=True)\n",
    "\n",
    "# creating over / under column (fill na with 0's)\n",
    "df.loc[((df.score_home + df.score_away) > df.over_under_line), 'over'] = 1\n",
    "df.over.fillna(0, inplace=True)\n",
    "\n",
    "# stadium neutral and schedule playoff as boolean\n",
    "df['stadium_neutral'] = df.stadium_neutral.astype(int)\n",
    "df['schedule_playoff'] = df.schedule_playoff.astype(int)\n",
    "\n",
    "# change data type of date columns\n",
    "df['schedule_date'] = pd.to_datetime(df['schedule_date'])\n",
    "games_elo['date'] = pd.to_datetime(games_elo['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19e0bb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fixing some schedule_week column errors and converting column to integer data type\n",
    "df.loc[(df.schedule_week == '18'), 'schedule_week'] = '17'\n",
    "df.loc[(df.schedule_week == 'Wildcard') | (df.schedule_week == 'WildCard'), 'schedule_week'] = '18'\n",
    "df.loc[(df.schedule_week == 'Division'), 'schedule_week'] = '19'\n",
    "df.loc[(df.schedule_week == 'Conference'), 'schedule_week'] = '20'\n",
    "df.loc[(df.schedule_week == 'Superbowl') | (df.schedule_week == 'SuperBowl'), 'schedule_week'] = '21'\n",
    "df['schedule_week'] = df.schedule_week.astype(int)\n",
    "\n",
    "# removing extra columns that aren't necessary for analysis\n",
    "df = df[['schedule_date', 'schedule_season', 'schedule_week', 'team_home',\n",
    "       'team_away', 'team_favorite_id', 'spread_favorite',\n",
    "       'over_under_line', 'weather_temperature',\n",
    "       'weather_wind_mph', 'score_home', 'score_away',\n",
    "       'stadium_neutral', 'home_favorite', 'away_favorite',\n",
    "       'over']]\n",
    "\n",
    "# Cleaning games_elo and df to merge correctly\n",
    "wsh_map = {'WSH' : 'WAS'}\n",
    "games_elo.loc[games_elo.team1 == 'WSH', 'team1'] = 'WAS' \n",
    "games_elo.loc[games_elo.team2 == 'WSH', 'team2'] = 'WAS'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ee04987",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix dates\n",
    "df.loc[(df.schedule_date == '2016-09-19') & (df.team_home == 'MIN'), 'schedule_date'] = datetime.datetime(2016, 9, 18)\n",
    "df.loc[(df.schedule_date == '2017-01-22') & (df.schedule_week == 21), 'schedule_date'] = datetime.datetime(2017, 2, 5)\n",
    "df.loc[(df.schedule_date == '1990-01-27') & (df.schedule_week == 21), 'schedule_date'] = datetime.datetime(1990, 1, 28)\n",
    "df.loc[(df.schedule_date == '1990-01-13'), 'schedule_date'] = datetime.datetime(1990, 1, 14)\n",
    "games_elo.loc[(games_elo.date == '2016-01-09'), 'date'] = datetime.datetime(2016, 1, 10)\n",
    "games_elo.loc[(games_elo.date == '2016-01-08'), 'date'] = datetime.datetime(2016, 1, 9)\n",
    "games_elo.loc[(games_elo.date == '2016-01-16'), 'date'] = datetime.datetime(2016, 1, 17)\n",
    "games_elo.loc[(games_elo.date == '2016-01-15'), 'date'] = datetime.datetime(2016, 1, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ba4ac1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge games_elo with df\n",
    "df = df.merge(games_elo, left_on=['schedule_date', 'team_home', 'team_away'], right_on=['date', 'team1', 'team2'], how='left')\n",
    "\n",
    "# merge to fix neutral games where team_home and team_away are switched\n",
    "games_elo2 = games_elo.rename(columns={'team1' : 'team2', 'team2' : 'team1', 'elo1_pre' : 'elo2_pre', 'elo2_pre' : 'elo1_pre'})\n",
    "games_elo2['qbelo_prob1'] = 1 - games_elo2.qbelo_prob1\n",
    "df = df.merge(games_elo2, left_on=['schedule_date', 'team_home', 'team_away'], right_on=['date', 'team1', 'team2'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b70c54b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separating merged columns into x and y cols\n",
    "x_cols = ['date_x', 'season_x', 'neutral_x', 'playoff_x', 'team1_x', 'team2_x', 'elo1_pre_x', 'elo2_pre_x',\n",
    "          'qbelo_prob1_x', 'score1_x', 'score2_x']\n",
    "y_cols = ['date_y', 'season_y', 'neutral_y', 'playoff_y', 'team1_y', 'team2_y', 'elo1_pre_y', 'elo2_pre_y',\n",
    "          'qbelo_prob1_y', 'score1_y', 'score2_y']\n",
    "\n",
    "# filling null values for games_elo merged cols\n",
    "for x, y in zip(x_cols, y_cols):\n",
    "    df[x] = df[x].fillna(df[y]) \n",
    "\n",
    "# removing y_cols from dataframe    \n",
    "df = df[['schedule_date', 'schedule_season', 'schedule_week', 'team_home',\n",
    "       'team_away', 'team_favorite_id', 'spread_favorite', 'over_under_line',\n",
    "       'weather_temperature', 'weather_wind_mph', 'score_home', 'score_away',\n",
    "       'stadium_neutral', 'home_favorite', 'away_favorite', 'over', 'neutral_x', 'playoff_x',\n",
    "         'elo1_pre_x', 'elo2_pre_x', 'qbelo_prob1_x']]\n",
    "\n",
    "# remove _x ending from column names\n",
    "df.columns = df.columns.str.replace('_x', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3470d88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating result column df.loc[(df.score_home > df.score_away), 'result'\n",
    "df['result'] = (df.score_home > df.score_away).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6723f05b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['schedule_date', 'schedule_season', 'schedule_week', 'team_home',\n",
      "       'team_away', 'team_favorite_id', 'spread_favorite', 'over_under_line',\n",
      "       'weather_temperature', 'weather_wind_mph', 'score_home', 'score_away',\n",
      "       'stadium_neutral', 'home_favorite', 'away_favorite', 'over', 'neutral',\n",
      "       'playoff', 'elo1_pre', 'elo2_pre', 'qbelo_prob1', 'result'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f229b14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  schedule_date  schedule_season  schedule_week team_home team_away  \\\n",
      "0    1979-09-01             1979              1        TB       DET   \n",
      "1    1979-09-02             1979              1       BUF       MIA   \n",
      "2    1979-09-02             1979              1       CHI        GB   \n",
      "3    1979-09-02             1979              1       DEN       CIN   \n",
      "4    1979-09-02             1979              1        KC       IND   \n",
      "5    1979-09-02             1979              1       LAR       OAK   \n",
      "6    1979-09-02             1979              1       MIN        SF   \n",
      "7    1979-09-02             1979              1        NO       ATL   \n",
      "8    1979-09-02             1979              1       NYJ       CLE   \n",
      "9    1979-09-02             1979              1       PHI       NYG   \n",
      "\n",
      "  team_favorite_id  spread_favorite  over_under_line  weather_temperature  \\\n",
      "0               TB             -3.0             30.0                 79.0   \n",
      "1              MIA             -5.0             39.0                 74.0   \n",
      "2              CHI             -3.0             31.0                 78.0   \n",
      "3              DEN             -3.0             31.5                 69.0   \n",
      "4               KC             -1.0             37.0                 76.0   \n",
      "5              LAR             -4.0             36.5                 70.0   \n",
      "6              MIN             -7.0             32.0                 70.0   \n",
      "7               NO             -5.0             32.0                 72.0   \n",
      "8              NYJ             -2.0             41.0                 73.0   \n",
      "9              PHI             -7.0             31.5                 76.0   \n",
      "\n",
      "   weather_wind_mph  ...  stadium_neutral  home_favorite  away_favorite  over  \\\n",
      "0               9.0  ...                0            1.0            0.0   1.0   \n",
      "1              15.0  ...                0            0.0            1.0   0.0   \n",
      "2              11.0  ...                0            1.0            0.0   0.0   \n",
      "3               6.0  ...                0            1.0            0.0   0.0   \n",
      "4               8.0  ...                0            1.0            0.0   0.0   \n",
      "5              10.0  ...                0            1.0            0.0   1.0   \n",
      "6              11.0  ...                0            1.0            0.0   1.0   \n",
      "7               0.0  ...                0            1.0            0.0   1.0   \n",
      "8              10.0  ...                0            1.0            0.0   1.0   \n",
      "9               9.0  ...                0            1.0            0.0   1.0   \n",
      "\n",
      "   neutral  playoff  elo1_pre  elo2_pre  qbelo_prob1  result  \n",
      "0      0.0      NaN  1385.204  1487.039     0.427168       1  \n",
      "1      0.0      NaN  1422.820  1573.513     0.375353       0  \n",
      "2      0.0      NaN  1485.806  1462.502     0.608396       1  \n",
      "3      0.0      NaN  1579.121  1491.380     0.675602       1  \n",
      "4      0.0      NaN  1408.082  1420.160     0.528007       1  \n",
      "5      0.0      NaN  1571.837  1543.108     0.617516       0  \n",
      "6      0.0      NaN  1501.070  1376.895     0.707520       1  \n",
      "7      0.0      NaN  1454.541  1472.748     0.563144       0  \n",
      "8      0.0      NaN  1486.703  1483.734     0.578964       0  \n",
      "9      0.0      NaN  1516.285  1435.862     0.686289       1  \n",
      "\n",
      "[10 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7705b9b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "schedule_date             0\n",
      "schedule_season           0\n",
      "schedule_week             0\n",
      "team_home               331\n",
      "team_away               336\n",
      "team_favorite_id          0\n",
      "spread_favorite           0\n",
      "over_under_line           0\n",
      "weather_temperature     454\n",
      "weather_wind_mph        454\n",
      "score_home                0\n",
      "score_away                0\n",
      "stadium_neutral           0\n",
      "home_favorite             0\n",
      "away_favorite             0\n",
      "over                      0\n",
      "neutral                 671\n",
      "playoff                9768\n",
      "elo1_pre                671\n",
      "elo2_pre                671\n",
      "qbelo_prob1             671\n",
      "result                    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.isnull().sum(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "48cbbcbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>schedule_season</th>\n",
       "      <td>10115.0</td>\n",
       "      <td>2000.004053</td>\n",
       "      <td>11.651364</td>\n",
       "      <td>1979.000000</td>\n",
       "      <td>1990.000000</td>\n",
       "      <td>2001.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>2019.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>schedule_week</th>\n",
       "      <td>10115.0</td>\n",
       "      <td>9.411567</td>\n",
       "      <td>5.197690</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>21.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spread_favorite</th>\n",
       "      <td>10115.0</td>\n",
       "      <td>-5.373950</td>\n",
       "      <td>3.430253</td>\n",
       "      <td>-26.500000</td>\n",
       "      <td>-7.000000</td>\n",
       "      <td>-4.500000</td>\n",
       "      <td>-3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>over_under_line</th>\n",
       "      <td>10115.0</td>\n",
       "      <td>41.936995</td>\n",
       "      <td>4.679488</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>38.500000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>63.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weather_temperature</th>\n",
       "      <td>9661.0</td>\n",
       "      <td>59.807991</td>\n",
       "      <td>15.438406</td>\n",
       "      <td>-6.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>97.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weather_wind_mph</th>\n",
       "      <td>9661.0</td>\n",
       "      <td>7.317669</td>\n",
       "      <td>5.704599</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score_home</th>\n",
       "      <td>10115.0</td>\n",
       "      <td>22.654375</td>\n",
       "      <td>10.393112</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>62.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score_away</th>\n",
       "      <td>10115.0</td>\n",
       "      <td>19.917252</td>\n",
       "      <td>10.049815</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>59.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stadium_neutral</th>\n",
       "      <td>10115.0</td>\n",
       "      <td>0.008304</td>\n",
       "      <td>0.090754</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>home_favorite</th>\n",
       "      <td>10115.0</td>\n",
       "      <td>0.647949</td>\n",
       "      <td>0.477634</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>away_favorite</th>\n",
       "      <td>10115.0</td>\n",
       "      <td>0.306772</td>\n",
       "      <td>0.461177</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>over</th>\n",
       "      <td>10115.0</td>\n",
       "      <td>0.484132</td>\n",
       "      <td>0.499773</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neutral</th>\n",
       "      <td>9444.0</td>\n",
       "      <td>0.007730</td>\n",
       "      <td>0.087583</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>elo1_pre</th>\n",
       "      <td>9444.0</td>\n",
       "      <td>1507.751027</td>\n",
       "      <td>98.951768</td>\n",
       "      <td>1197.301000</td>\n",
       "      <td>1438.777220</td>\n",
       "      <td>1507.863000</td>\n",
       "      <td>1576.241750</td>\n",
       "      <td>1849.484000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>elo2_pre</th>\n",
       "      <td>9444.0</td>\n",
       "      <td>1506.683283</td>\n",
       "      <td>97.140716</td>\n",
       "      <td>1201.561463</td>\n",
       "      <td>1438.989771</td>\n",
       "      <td>1508.227500</td>\n",
       "      <td>1576.294250</td>\n",
       "      <td>1825.961000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qbelo_prob1</th>\n",
       "      <td>9444.0</td>\n",
       "      <td>0.575591</td>\n",
       "      <td>0.171854</td>\n",
       "      <td>0.059810</td>\n",
       "      <td>0.453909</td>\n",
       "      <td>0.587001</td>\n",
       "      <td>0.706974</td>\n",
       "      <td>0.967197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>result</th>\n",
       "      <td>10115.0</td>\n",
       "      <td>0.579041</td>\n",
       "      <td>0.493737</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       count         mean        std          min  \\\n",
       "schedule_season      10115.0  2000.004053  11.651364  1979.000000   \n",
       "schedule_week        10115.0     9.411567   5.197690     1.000000   \n",
       "spread_favorite      10115.0    -5.373950   3.430253   -26.500000   \n",
       "over_under_line      10115.0    41.936995   4.679488    28.000000   \n",
       "weather_temperature   9661.0    59.807991  15.438406    -6.000000   \n",
       "weather_wind_mph      9661.0     7.317669   5.704599     0.000000   \n",
       "score_home           10115.0    22.654375  10.393112     0.000000   \n",
       "score_away           10115.0    19.917252  10.049815     0.000000   \n",
       "stadium_neutral      10115.0     0.008304   0.090754     0.000000   \n",
       "home_favorite        10115.0     0.647949   0.477634     0.000000   \n",
       "away_favorite        10115.0     0.306772   0.461177     0.000000   \n",
       "over                 10115.0     0.484132   0.499773     0.000000   \n",
       "neutral               9444.0     0.007730   0.087583     0.000000   \n",
       "elo1_pre              9444.0  1507.751027  98.951768  1197.301000   \n",
       "elo2_pre              9444.0  1506.683283  97.140716  1201.561463   \n",
       "qbelo_prob1           9444.0     0.575591   0.171854     0.059810   \n",
       "result               10115.0     0.579041   0.493737     0.000000   \n",
       "\n",
       "                             25%          50%          75%          max  \n",
       "schedule_season      1990.000000  2001.000000  2010.000000  2019.000000  \n",
       "schedule_week           5.000000    10.000000    14.000000    21.000000  \n",
       "spread_favorite        -7.000000    -4.500000    -3.000000     0.000000  \n",
       "over_under_line        38.500000    42.000000    45.000000    63.500000  \n",
       "weather_temperature    49.000000    63.000000    72.000000    97.000000  \n",
       "weather_wind_mph        1.000000     8.000000    11.000000    40.000000  \n",
       "score_home             16.000000    22.000000    30.000000    62.000000  \n",
       "score_away             13.000000    20.000000    27.000000    59.000000  \n",
       "stadium_neutral         0.000000     0.000000     0.000000     1.000000  \n",
       "home_favorite           0.000000     1.000000     1.000000     1.000000  \n",
       "away_favorite           0.000000     0.000000     1.000000     1.000000  \n",
       "over                    0.000000     0.000000     1.000000     1.000000  \n",
       "neutral                 0.000000     0.000000     0.000000     1.000000  \n",
       "elo1_pre             1438.777220  1507.863000  1576.241750  1849.484000  \n",
       "elo2_pre             1438.989771  1508.227500  1576.294250  1825.961000  \n",
       "qbelo_prob1             0.453909     0.587001     0.706974     0.967197  \n",
       "result                  0.000000     1.000000     1.000000     1.000000  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "991d83a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some percentages to take into consideration when betting\n",
    "home_win = \"{:.2f}\".format((sum((df.result == 1) & (df.stadium_neutral == 0)) / len(df)) * 100)\n",
    "away_win = \"{:.2f}\".format((sum((df.result == 0) & (df.stadium_neutral == 0)) / len(df)) * 100)\n",
    "under_line = \"{:.2f}\".format((sum((df.score_home + df.score_away) < df.over_under_line) / len(df)) * 100)\n",
    "over_line = \"{:.2f}\".format((sum((df.score_home + df.score_away) > df.over_under_line) / len(df)) * 100)\n",
    "\n",
    "favored = \"{:.2f}\".format((sum(((df.home_favorite == 1) & (df.result == 1)) | ((df.away_favorite == 1) & (df.result == 0)))\n",
    "                           / len(df)) * 100)\n",
    "\n",
    "cover = \"{:.2f}\".format((sum(((df.home_favorite == 1) & ((df.score_away - df.score_home) < df.spread_favorite)) | \n",
    "                             ((df.away_favorite == 1) & ((df.score_home - df.score_away) < df.spread_favorite))) \n",
    "                         / len(df)) * 100)\n",
    "\n",
    "ats = \"{:.2f}\".format((sum(((df.home_favorite == 1) & ((df.score_away - df.score_home) > df.spread_favorite)) | \n",
    "                           ((df.away_favorite == 1) & ((df.score_home - df.score_away) > df.spread_favorite))) \n",
    "                       / len(df)) * 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f5d4b509",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Games: 10115\n",
      "Home Straight Up Win Percentage: 57.52%\n",
      "Away Straight Up Win Percentage: 41.65%\n",
      "Under Percentage: 49.74%\n",
      "Over Percentage: 48.41%\n",
      "Favored Win Percentage: 63.16%\n",
      "Cover The Spread Percentage: 45.05%\n",
      "Against The Spread Percentage: 47.73%\n"
     ]
    }
   ],
   "source": [
    "# print all percentages\n",
    "print(\"Number of Games: \" + str(len(df)))\n",
    "print(\"Home Straight Up Win Percentage: \" + home_win + \"%\")\n",
    "print(\"Away Straight Up Win Percentage: \" + away_win + \"%\")\n",
    "print(\"Under Percentage: \" + under_line + \"%\")\n",
    "print(\"Over Percentage: \" + over_line + \"%\")\n",
    "print(\"Favored Win Percentage: \" + favored + \"%\")\n",
    "print(\"Cover The Spread Percentage: \" + cover + \"%\")\n",
    "print(\"Against The Spread Percentage: \" + ats + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a966c186",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating 2 separate dataframes with the home teams / scores and the away teams / scores\n",
    "score = df.groupby(['schedule_season', 'schedule_week', 'team_home']).mean()[['score_home', 'score_away']].reset_index()\n",
    "aw_score = df.groupby(['schedule_season', 'schedule_week', 'team_away']).mean()[['score_home', 'score_away']].reset_index()\n",
    "\n",
    "# create total pts column\n",
    "score['point_diff'] = score.score_home - score.score_away\n",
    "aw_score['point_diff'] = aw_score.score_away - aw_score.score_home\n",
    "\n",
    "# append the two dataframes\n",
    "score = score.append(aw_score, ignore_index=True, sort=True)\n",
    "\n",
    "# fill null values\n",
    "score.team_home.fillna(score.team_away, inplace=True)\n",
    "\n",
    "# sort by season and week \n",
    "score.sort_values(['schedule_season', 'schedule_week'], ascending = [True, True], inplace=True)\n",
    "\n",
    "# removing unneeded columns & changing column name \n",
    "score = score[['schedule_season', 'schedule_week', 'team_home', 'point_diff']]\n",
    "score.rename(columns={'team_home' : 'team'}, inplace=True)\n",
    "\n",
    "# dictionary of dataframes - separate dataframe for each team\n",
    "tm_dict = {}\n",
    "for key in score.team.unique():\n",
    "    tm_dict[key] = score[score.team == key].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "79693c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe to populate\n",
    "pts_diff = pd.DataFrame()\n",
    "\n",
    "# for loop to create a rolling average of the previous games for each season\n",
    "for yr in score.schedule_season.unique():\n",
    "    for tm in score.team.unique():\n",
    "        data = tm_dict[tm].copy()\n",
    "        data = data[data.schedule_season == yr]\n",
    "        \n",
    "        data.loc[:, 'avg_pts_diff'] = data.point_diff.shift().expanding().mean()\n",
    "        \n",
    "        pts_diff = pts_diff.append(data)\n",
    "\n",
    "\n",
    "# merging to df and changing column names\n",
    "df = df.merge(pts_diff[['schedule_season', 'schedule_week', 'team', 'avg_pts_diff']], \n",
    "              left_on=['schedule_season', 'schedule_week', 'team_home'], right_on=['schedule_season', 'schedule_week', 'team'],\n",
    "              how='left')\n",
    "\n",
    "df.rename(columns={'avg_pts_diff' : 'hm_avg_pts_diff'}, inplace=True)\n",
    "\n",
    "df = df.merge(pts_diff[['schedule_season', 'schedule_week', 'team', 'avg_pts_diff']], \n",
    "              left_on=['schedule_season', 'schedule_week', 'team_away'], right_on=['schedule_season', 'schedule_week', 'team'],\n",
    "              how='left')\n",
    "\n",
    "df.rename(columns={'avg_pts_diff' : 'aw_avg_pts_diff'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "286ac64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# average point differential over entire season\n",
    "total_season = pts_diff.groupby(['schedule_season', 'team']).mean()['point_diff'].reset_index()\n",
    "\n",
    "\n",
    "# adding schedule week for merge and adding one to the season for predictions\n",
    "total_season['schedule_week'] = 1\n",
    "total_season['schedule_season'] += 1\n",
    "\n",
    "\n",
    "# differentials for start of the year\n",
    "# total_season.to_csv(\"pointdiff2019.csv\", index=False)\n",
    "\n",
    "\n",
    "# cleaning of columns\n",
    "df = df[['schedule_date', 'schedule_season', 'schedule_week', 'team_home',\n",
    "       'team_away', 'team_favorite_id', 'spread_favorite', 'over_under_line',\n",
    "       'weather_temperature', 'weather_wind_mph', 'score_home', 'score_away', 'stadium_neutral', 'home_favorite',\n",
    "       'away_favorite', 'hm_avg_pts_diff','aw_avg_pts_diff', 'elo1_pre', 'elo2_pre', 'qbelo_prob1', 'over', 'result']]\n",
    "\n",
    "\n",
    "# merge to have previous seasons average point differential\n",
    "df = df.merge(total_season[['schedule_season', 'schedule_week', 'team', 'point_diff']], \n",
    "              left_on=['schedule_season', 'schedule_week', 'team_home'], right_on=['schedule_season', 'schedule_week', 'team'],\n",
    "              how='left')\n",
    "\n",
    "df.rename(columns={'point_diff' : 'hm_avg_diff'}, inplace=True)\n",
    "\n",
    "df = df.merge(total_season[['schedule_season', 'schedule_week', 'team', 'point_diff']], \n",
    "              left_on=['schedule_season', 'schedule_week', 'team_away'], right_on=['schedule_season', 'schedule_week', 'team'],\n",
    "              how='left')\n",
    "\n",
    "df.rename(columns={'point_diff' : 'aw_avg_diff'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a0b7e238",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill null values\n",
    "df.hm_avg_pts_diff.fillna(df.hm_avg_diff, inplace=True)\n",
    "df.aw_avg_pts_diff.fillna(df.aw_avg_diff, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8e60febd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning of columns\n",
    "df = df[['schedule_date', 'schedule_season', 'schedule_week', 'team_home',\n",
    "       'team_away', 'team_favorite_id', 'spread_favorite', 'over_under_line',\n",
    "       'weather_temperature', 'weather_wind_mph', 'score_home', 'score_away', 'stadium_neutral', 'home_favorite',\n",
    "       'away_favorite', 'hm_avg_pts_diff','aw_avg_pts_diff', 'elo1_pre', 'elo2_pre', 'qbelo_prob1', 'over', 'result']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d847e5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing all rows with null values\n",
    "df = df.dropna(how='any',axis=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9f8e08ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Feature and Model Testing \n",
    "\n",
    "# initial features possible for model\n",
    "X = df[['schedule_season', 'schedule_week', 'over_under_line', 'spread_favorite', 'weather_temperature', 'weather_wind_mph',\n",
    "        'home_favorite', 'hm_avg_pts_diff','aw_avg_pts_diff', 'elo1_pre', 'elo2_pre', 'qbelo_prob1']]\n",
    "\n",
    "y = df['result']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7967462b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False False False  True  True False  True  True  True False False  True]\n",
      "[3 4 7 1 1 2 1 1 1 6 5 1]\n"
     ]
    }
   ],
   "source": [
    "# base model\n",
    "base = LDA()\n",
    "\n",
    "# choose 5 best features\n",
    "rfe = RFE(base)\n",
    "rfe = rfe.fit(X, y)\n",
    "\n",
    "# features\n",
    "print(rfe.support_)\n",
    "print(rfe.ranking_)\n",
    "\n",
    "\n",
    "# best 5 features chosen by the RFE base model\n",
    "final_x = df[['spread_favorite', 'home_favorite', 'hm_avg_pts_diff', 'elo2_pre', 'qbelo_prob1']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7439df51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare models\n",
    "models = []\n",
    "\n",
    "models.append(('LRG', LogisticRegression(solver='liblinear')))\n",
    "models.append(('KNB', KNeighborsClassifier()))\n",
    "models.append(('GNB', GaussianNB()))\n",
    "models.append(('XGB', xgb.XGBClassifier(random_state=0)))\n",
    "models.append(('RFC', RandomForestClassifier(random_state=0, n_estimators=100)))\n",
    "models.append(('DTC', DecisionTreeClassifier(random_state=0, criterion='entropy', max_depth=5)))\n",
    "\n",
    "# evaluate each model by average and standard deviations of roc auc \n",
    "results = []\n",
    "names = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "70f7df77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LRG: 0.691861 (0.020426)\n",
      "KNB: 0.615944 (0.007793)\n",
      "GNB: 0.690562 (0.019565)\n",
      "XGB: 0.655039 (0.017223)\n",
      "RFC: 0.658653 (0.016107)\n",
      "DTC: 0.684090 (0.015020)\n"
     ]
    }
   ],
   "source": [
    "for name, m in models:\n",
    "    kfold = model_selection.KFold(n_splits=5, random_state=None)\n",
    "    cv_results = model_selection.cross_val_score(m, final_x, y, cv=kfold, scoring = 'roc_auc')\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "43a965d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training and testing data (2017 and 2018)\n",
    "train = df.copy()\n",
    "test = df.copy()\n",
    "train = train.loc[train['schedule_season'] < 2017]\n",
    "test = test.loc[test['schedule_season'] > 2016]\n",
    "X_train = train[['over_under_line', 'spread_favorite', 'home_favorite', 'hm_avg_pts_diff', 'qbelo_prob1']]\n",
    "y_train = train['result']\n",
    "X_test = test[['over_under_line', 'spread_favorite', 'home_favorite', 'hm_avg_pts_diff', 'qbelo_prob1']]\n",
    "y_test = test['result']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1d85105d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calibrate probabilities and fit model to training data\n",
    "boost = xgb.XGBClassifier()\n",
    "dtc = DecisionTreeClassifier(max_depth=5, criterion='entropy')\n",
    "lrg = LogisticRegression(solver='liblinear')\n",
    "vote = VotingClassifier(estimators=[('boost', boost), ('dtc', dtc), ('lrg', lrg)], voting='soft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d4d23881",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CalibratedClassifierCV(base_estimator=VotingClassifier(estimators=[('boost',\n",
       "                                                                    XGBClassifier(base_score=None,\n",
       "                                                                                  booster=None,\n",
       "                                                                                  callbacks=None,\n",
       "                                                                                  colsample_bylevel=None,\n",
       "                                                                                  colsample_bynode=None,\n",
       "                                                                                  colsample_bytree=None,\n",
       "                                                                                  early_stopping_rounds=None,\n",
       "                                                                                  enable_categorical=False,\n",
       "                                                                                  eval_metric=None,\n",
       "                                                                                  gamma=None,\n",
       "                                                                                  gpu_id=None,\n",
       "                                                                                  grow_policy=None,\n",
       "                                                                                  importance_type=None,\n",
       "                                                                                  interaction_constra...\n",
       "                                                                                  max_depth=None,\n",
       "                                                                                  max_leaves=None,\n",
       "                                                                                  min_child_weight=None,\n",
       "                                                                                  missing=nan,\n",
       "                                                                                  monotone_constraints=None,\n",
       "                                                                                  n_estimators=100,\n",
       "                                                                                  n_jobs=None,\n",
       "                                                                                  num_parallel_tree=None,\n",
       "                                                                                  predictor=None,\n",
       "                                                                                  random_state=None,\n",
       "                                                                                  reg_alpha=None,\n",
       "                                                                                  reg_lambda=None, ...)),\n",
       "                                                                   ('dtc',\n",
       "                                                                    DecisionTreeClassifier(criterion='entropy',\n",
       "                                                                                           max_depth=5)),\n",
       "                                                                   ('lrg',\n",
       "                                                                    LogisticRegression(solver='liblinear'))],\n",
       "                                                       voting='soft'),\n",
       "                       cv=3, method='isotonic')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CCV(vote, method='isotonic', cv=3)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ba6c48dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict probabilities\n",
    "predicted = model.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "838068b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics\t\tMy Model\tElo Results\n",
      "ROC AUC Score: \t0.7033\t\t0.6908\n",
      "Brier Score: \t0.2142\t\t0.2163\n"
     ]
    }
   ],
   "source": [
    "# ROC AUC Score higher is better while Brier Score the lower the better\n",
    "print(\"Metrics\" + \"\\t\\t\" + \"My Model\" + \"\\t\" + \"Elo Results\")\n",
    "print(\"ROC AUC Score: \" +  \"\\t\" + \"{:.4f}\".format(roc_auc_score(y_test, predicted)) + \"\\t\\t\" + \"{:.4f}\".format(roc_auc_score(test.result, test.qbelo_prob1)))\n",
    "print(\"Brier Score: \" + \"\\t\" + \"{:.4f}\".format(brier_score_loss(y_test, predicted)) + \"\\t\\t\" + \"{:.4f}\".format(brier_score_loss(test.result, test.qbelo_prob1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "18c503f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a column with the models probabilities to analyze vs elo fivethirtyeight\n",
    "test.loc[:,'hm_prob'] = predicted\n",
    "test = test[['schedule_season', 'schedule_week', 'team_home', 'team_away', 'qbelo_prob1', 'hm_prob', 'result']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6903656b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calulate bets won (only make a bet when probability is greater than / equal to 60% or less than / equal to 40%)\n",
    "test['my_bet_won'] = (((test.hm_prob >= 0.60) & (test.result == 1)) | ((test.hm_prob <= 0.40) & (test.result == 0))).astype(int)\n",
    "test['elo_bet_won'] = (((test.qbelo_prob1 >= 0.60) & (test.result == 1)) | ((test.qbelo_prob1 <= 0.40) & (test.result == 0))).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "45583f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calulate bets lost (only make a bet when probability is greater than / equal to 60% or less than / equal to 40%)\n",
    "test['my_bet_lost'] = (((test.hm_prob >= 0.60) & (test.result == 0)) | ((test.hm_prob <= 0.40) & (test.result == 1))).astype(int)\n",
    "test['elo_bet_lost'] = (((test.qbelo_prob1 >= 0.60) & (test.result == 0)) | ((test.qbelo_prob1 <= 0.40) & (test.result == 1))).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "641ce030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My Model Win Percentage: 0.7157\n",
      "Total Number of Bets Won: 287\n",
      "Total Number of Bets Made: 401\n",
      "Possible Games: 557\n"
     ]
    }
   ],
   "source": [
    "# printing some quick overall results for my model\n",
    "print(\"My Model Win Percentage: \" + \"{:.4f}\".format(test.my_bet_won.sum() / (test.my_bet_lost.sum() + test.my_bet_won.sum())))\n",
    "print(\"Total Number of Bets Won: \" + str(test.my_bet_won.sum()))\n",
    "print(\"Total Number of Bets Made: \" + str((test.my_bet_lost.sum() + test.my_bet_won.sum())))\n",
    "print(\"Possible Games: \" + str(len(test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c5875ba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ELO Model Win Percentage: 0.6960\n",
      "Total Number of Bets Won: 261\n",
      "Total Number of Bets Made: 375\n",
      "Possible Games: 557\n"
     ]
    }
   ],
   "source": [
    "# printing some quick overall results for fivethirtyeight's ELO model\n",
    "print(\"ELO Model Win Percentage: \" + \"{:.4f}\".format(test.elo_bet_won.sum()/(test.elo_bet_lost.sum() + test.elo_bet_won.sum())))\n",
    "print(\"Total Number of Bets Won: \" + str(test.elo_bet_won.sum()))\n",
    "print(\"Total Number of Bets Made: \" + str((test.elo_bet_lost.sum() + test.elo_bet_won.sum())))\n",
    "print(\"Possible Games: \" + str(len(test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "91a2ad5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating week by week results\n",
    "results_df = test.groupby(['schedule_season', 'schedule_week']).agg({'team_home' : 'count', 'my_bet_won' : 'sum', \n",
    "'elo_bet_won' : 'sum', 'my_bet_lost' : 'sum', 'elo_bet_lost' : 'sum'}).reset_index().rename(columns=\n",
    "                                                                                            {'team_home' : 'total_games'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5d0fb82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# counting total bets for my model and the ELO model (prob >= 60% or prob <= 40%)\n",
    "results_df['total_bets'] = results_df.my_bet_won + results_df.my_bet_lost\n",
    "results_df['elo_total_bets'] = results_df.elo_bet_won + results_df.elo_bet_lost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "46ff805e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating accuracy columns based on bets made not on total games\n",
    "results_df['bet_accuracy'] = round((results_df.my_bet_won / results_df.total_bets) * 100, 2)\n",
    "results_df['elo_bet_accuracy'] = round((results_df.elo_bet_won / results_df.elo_total_bets) * 100, 2)\n",
    "results_df = results_df[['schedule_season', 'schedule_week', 'bet_accuracy', 'elo_bet_accuracy',\n",
    "                         'total_bets', 'elo_total_bets', 'total_games']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6774db7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    schedule_season  schedule_week  bet_accuracy  elo_bet_accuracy  \\\n",
      "0              2017              1         80.00             77.78   \n",
      "1              2017              2         80.00            100.00   \n",
      "2              2017              3         72.73             55.56   \n",
      "3              2017              4         60.00             66.67   \n",
      "4              2017              5         50.00             50.00   \n",
      "5              2017              6         40.00             36.36   \n",
      "6              2017              7        100.00             81.82   \n",
      "7              2017              8        100.00            100.00   \n",
      "8              2017              9         85.71             83.33   \n",
      "9              2017             10         80.00             80.00   \n",
      "10             2017             11         83.33             71.43   \n",
      "11             2017             12         84.62             75.00   \n",
      "12             2017             13         81.82             80.00   \n",
      "13             2017             14         60.00             42.86   \n",
      "14             2017             15        100.00             81.82   \n",
      "15             2017             16         76.92             85.71   \n",
      "16             2017             17         72.73             50.00   \n",
      "17             2017             18         50.00             66.67   \n",
      "18             2017             19         66.67             66.67   \n",
      "19             2017             20        100.00            100.00   \n",
      "20             2017             21          0.00              0.00   \n",
      "21             2018              1         70.00             60.00   \n",
      "22             2018              2         60.00             83.33   \n",
      "23             2018              3         60.00             50.00   \n",
      "24             2018              4         75.00             72.73   \n",
      "25             2018              5         77.78             66.67   \n",
      "26             2018              6         87.50             87.50   \n",
      "27             2018              7         55.56             71.43   \n",
      "28             2018              8        100.00            100.00   \n",
      "29             2018              9         75.00             83.33   \n",
      "30             2018             10         63.64             66.67   \n",
      "31             2018             11         66.67             42.86   \n",
      "32             2018             12         77.78             69.23   \n",
      "33             2018             13         53.33             58.33   \n",
      "34             2018             14         61.54             44.44   \n",
      "35             2018             15         60.00             66.67   \n",
      "36             2018             16         72.73             75.00   \n",
      "37             2018             17         76.92             83.33   \n",
      "38             2018             18         25.00             25.00   \n",
      "39             2018             19        100.00            100.00   \n",
      "40             2018             20          0.00              0.00   \n",
      "41             2018             21          0.00               NaN   \n",
      "42             2019              1        100.00            100.00   \n",
      "43             2019              2        100.00            100.00   \n",
      "44             2019              3        100.00             50.00   \n",
      "45             2019              4         50.00             40.00   \n",
      "46             2019              5         66.67             66.67   \n",
      "47             2019              6           NaN               NaN   \n",
      "48             2019              7        100.00               NaN   \n",
      "49             2019              8        100.00            100.00   \n",
      "50             2019              9        100.00            100.00   \n",
      "51             2019             10          0.00              0.00   \n",
      "52             2019             11        100.00            100.00   \n",
      "53             2019             12        100.00             66.67   \n",
      "54             2019             13         60.00             75.00   \n",
      "55             2019             14         50.00             50.00   \n",
      "56             2019             15         66.67             66.67   \n",
      "57             2019             16        100.00            100.00   \n",
      "58             2019             17        100.00            100.00   \n",
      "59             2019             18         50.00             50.00   \n",
      "\n",
      "    total_bets  elo_total_bets  total_games  \n",
      "0           10               9           14  \n",
      "1           10               7           13  \n",
      "2           11               9           15  \n",
      "3           10               9           15  \n",
      "4           10               6           14  \n",
      "5           10              11           13  \n",
      "6            8              11           14  \n",
      "7            9               8           12  \n",
      "8            7               6           12  \n",
      "9           10              10           13  \n",
      "10           6               7           13  \n",
      "11          13              12           15  \n",
      "12          11              10           15  \n",
      "13          10               7           15  \n",
      "14           9              11           15  \n",
      "15          13              14           15  \n",
      "16          11              10           15  \n",
      "17           4               3            4  \n",
      "18           3               3            4  \n",
      "19           2               1            2  \n",
      "20           1               1            1  \n",
      "21          10              10           15  \n",
      "22          10               6           15  \n",
      "23          10              10           15  \n",
      "24           8              11           15  \n",
      "25           9               9           14  \n",
      "26           8               8           14  \n",
      "27           9               7           13  \n",
      "28           7               8           13  \n",
      "29           8               6           12  \n",
      "30          11              12           13  \n",
      "31           9               7           12  \n",
      "32           9              13           14  \n",
      "33          15              12           15  \n",
      "34          13               9           15  \n",
      "35          10               9           15  \n",
      "36          11              12           15  \n",
      "37          13              12           15  \n",
      "38           4               4            4  \n",
      "39           4               4            4  \n",
      "40           2               2            2  \n",
      "41           1               0            1  \n",
      "42           2               2            3  \n",
      "43           1               1            3  \n",
      "44           1               2            3  \n",
      "45           4               5            6  \n",
      "46           3               3            3  \n",
      "47           0               0            1  \n",
      "48           2               0            4  \n",
      "49           5               5            5  \n",
      "50           1               1            1  \n",
      "51           2               2            3  \n",
      "52           1               1            2  \n",
      "53           2               3            3  \n",
      "54           5               4            6  \n",
      "55           4               2            4  \n",
      "56           3               3            4  \n",
      "57           2               2            2  \n",
      "58           2               1            2  \n",
      "59           2               2            2  \n"
     ]
    }
   ],
   "source": [
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4d0730b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model as pkl file for weekly predictions\n",
    "pkl_filename = \"NFLMoneyLine_model1.pkl\"\n",
    "with open(pkl_filename, 'wb') as file:\n",
    "    pickle.dump(model, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6511a949",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
